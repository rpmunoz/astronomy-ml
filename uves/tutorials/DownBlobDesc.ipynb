{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "------------------------------------------------------------------------------\n",
    " This script download the descriptors to be used in the tutoial.\n",
    " It needs account information:\n",
    "   - Account name.\n",
    "   - Account key.\n",
    " It needs the blob container information\n",
    "   - Container name\n",
    "   - Container sub-directory\n",
    "------------------------------------------------------------------------------\n",
    "'''\n",
    "import os, uuid, sys\n",
    "import subprocess\n",
    "import tqdm\n",
    "import astropy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import random\n",
    "\n",
    "from io import BytesIO\n",
    "from astropy.io import fits\n",
    "from functools import partial\n",
    "from azure.storage.blob import BlockBlobService, PublicAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the BlockBlockService that is used to call the Blob service \n",
    "# for the storage account\n",
    "import config_blob_keys as cfg\n",
    "\n",
    "account_name = cfg.AccountName\n",
    "account_key = cfg.AccountKey\n",
    "block_blob_service = BlockBlobService(account_name=account_name, account_key=account_key)\n",
    "\n",
    "# The cointainer where the .fits are\n",
    "cont_name_desc = 'descriptor'\n",
    "# Set the permission so the blobs are public.\n",
    "block_blob_service.set_container_acl(cont_name_desc, public_access=PublicAccess.Container)\n",
    "\n",
    "# The cointainer where the .fits are\n",
    "cont_name_desc_cor = 'descriptorcorrupt'\n",
    "# Set the permission so the blobs are public.\n",
    "block_blob_service.set_container_acl(cont_name_desc_cor, public_access=PublicAccess.Container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to move files in azure cloud\n",
    "\n",
    "# Create a list \"filelist\" with the blob content\n",
    "# inside the \"Azure:container/folder\" location \n",
    "def BlobList(container, folder, filelist, verbose=False):\n",
    "    \n",
    "    gen = block_blob_service.list_blobs(container, prefix=folder)\n",
    "    \n",
    "    for blob in gen:\n",
    "        file = str(blob.name).replace(folder,'')\n",
    "        filelist.append(file)\n",
    "        if verbose == True:\n",
    "            print(\"\\t Blob name: \" + blob.name)\n",
    "        \n",
    "    return filelist\n",
    "\n",
    "# Download a file \"blobfile\" from \"container\" and save it \n",
    "# in the file \"locfile\"\n",
    "def DownBlob(container, blobfile, locfile, verbose=False):\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('Downloading ' + blobfile + ' to ' + locfile)\n",
    "    \n",
    "    block_blob_service.get_blob_to_path(container, blobfile, locfile)\n",
    "\n",
    "# Uncompress data \n",
    "def UnCompress(file, verbose=False):\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('Uncompressing ' + file)\n",
    "    \n",
    "    subprocess.call(['uncompress', file])\n",
    "    #os.popen('uncompress ' + file)\n",
    "\n",
    "# Upload file \"locfile\" to the blob \"blobfile\" in container\n",
    "def UpBlob(container, blobfile, locfile, verbose=False):\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('Uploading ' + locfile + ' to ' + blobfile)\n",
    "        \n",
    "    block_blob_service.create_blob_from_path(container, blobfile, locfile, validate_content=True)\n",
    "\n",
    "# Select descriptors file from a list\n",
    "def SelectDesc(path_loc, cont_name, desc_blob_sub_dir, file, verbose=False):       \n",
    "    # Download descriptors\n",
    "    desc_blob_name = os.path.join(desc_blob_sub_dir,file)\n",
    "    path_to_file_loc = os.path.join(path_loc, file)\n",
    "    \n",
    "    DownBlob(cont_name, desc_blob_name, path_to_file_loc, False)\n",
    "    \n",
    "    while not os.path.exists(path_to_file_loc):\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on UVES_BLUE_WAVE...\n",
      "Good files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424402e9474e4866a2cf320fede5f40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './desc_for_test/method2/good/UVES_BLUE_WAVE/ext1/UVES.2011-10-31T10:26:00.867_desc.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/data/anaconda3/envs/eso/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"<ipython-input-70-8409037fe837>\", line 49, in SelectDesc\n    DownBlob(cont_name, desc_blob_name, path_to_file_loc, False)\n  File \"<ipython-input-70-8409037fe837>\", line 24, in DownBlob\n    block_blob_service.get_blob_to_path(container, blobfile, locfile)\n  File \"/data/anaconda3/envs/eso/lib/python3.6/site-packages/azure/storage/blob/baseblobservice.py\", line 1968, in get_blob_to_path\n    with open(file_path, open_mode) as stream:\nFileNotFoundError: [Errno 2] No such file or directory: './desc_for_test/method2/good/UVES_BLUE_WAVE/ext1/UVES.2011-10-31T10:26:00.867_desc.npy'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-18ea8646d1d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSelectDesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgood_path_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_name_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_folder_rem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_files_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc_files_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# List the bad garchim descriptor files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/eso/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/eso/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1015\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/eso/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './desc_for_test/method2/good/UVES_BLUE_WAVE/ext1/UVES.2011-10-31T10:26:00.867_desc.npy'"
     ]
    }
   ],
   "source": [
    "# Download the images to ../data/desc_for_test/UVES_*\n",
    "#DescBlobSubDirs = ['UVES_BLUE_BIAS','UVES_DIC1B_DFLAT']\n",
    "DescBlobSubDirs = ['UVES_BLUE_WAVE']\n",
    "# Root local path\n",
    "method_dir = 'numpy/method2' # Do not put a '/' at the beggining!!!\n",
    "path_loc = './desc_for_test/method2'\n",
    "random.seed(100)\n",
    "# Maximum number of files for dowload\n",
    "nmax = 30\n",
    "bad_files_garchim = []\n",
    "\n",
    "# loop for descriptors folders\n",
    "for desc_blob_sub_dir in DescBlobSubDirs:\n",
    "    \n",
    "    print('Working on ' + desc_blob_sub_dir + '...')\n",
    "    # Define the image type\n",
    "    if desc_blob_sub_dir == 'UVES_BLUE_BIAS':\n",
    "        image_type = 'bias_blue'\n",
    "    elif desc_blob_sub_dir == 'UVES_RED_BIAS':\n",
    "        image_type = 'bias_red'\n",
    "    elif desc_blob_sub_dir == 'UVES_BLUE_WAVE' or desc_blob_sub_dir == 'UVES_DIC1B_FLAT' or desc_blob_sub_dir == 'UVES_DIC1B_DFLAT':\n",
    "        image_type = 'blue_arc_flat'\n",
    "    elif desc_blob_sub_dir == 'UVES_RED_WAVE' or desc_blob_sub_dir == 'UVES_DIC1R_FLAT':\n",
    "        image_type = 'red_arc_flat'\n",
    "        \n",
    "    if desc_blob_sub_dir == 'UVES_BLUE_BIAS' or desc_blob_sub_dir == 'UVES_DIC1B_FLAT' or desc_blob_sub_dir == 'UVES_DIC1B_DFLAT':\n",
    "        Exten = 0\n",
    "    elif desc_blob_sub_dir == 'UVES_RED_BIAS' or desc_blob_sub_dir == 'UVES_BLUE_WAVE' or desc_blob_sub_dir == 'UVES_RED_WAVE' or desc_blob_sub_dir == 'UVES_DIC1R_FLAT':\n",
    "        Exten = 1#,2]\n",
    "        \n",
    "    extension = '/ext' + str(Exten)\n",
    "    \n",
    "    # Take the Garchim bad images name\n",
    "    PROJECT_DIR = \"/data/notebooks/uves_jprieto\"\n",
    "    DATA_DIR = os.path.join(PROJECT_DIR, \"data\")\n",
    "    uves_flag_file = os.path.join(DATA_DIR, 'UVES_hidden_flag_results.txt')\n",
    "    uves_flag_df = pd.read_csv(uves_flag_file, comment='#', sep=';')\n",
    "    uves_flag_df['filename'] = uves_flag_df['filename']+'_desc.npy'\n",
    "    corrupted_df = uves_flag_df[(uves_flag_df['image_type'] == image_type) & (uves_flag_df['flag'] == 'CORRUPTED')]\n",
    "    bad_files_garchim = list(corrupted_df['filename'])     \n",
    "\n",
    "    # List the good descriptor files\n",
    "    print('Good files...')\n",
    "    desc_files_list = []\n",
    "    desc_folder_rem = method_dir + '/' + desc_blob_sub_dir + extension\n",
    "    BlobList(cont_name_desc, desc_folder_rem, desc_files_list)\n",
    "    good_path_loc = path_loc + '/good/' + desc_blob_sub_dir + extension\n",
    "\n",
    "    # Erase corrupted files from the list\n",
    "    desc_files_list = [s.replace('/','') for s in desc_files_list if s not in bad_files_garchim]\n",
    "    nfiles = len(desc_files_list)\n",
    "    random.shuffle(desc_files_list)\n",
    "    \n",
    "    if nfiles>nmax:\n",
    "        desc_files_list = desc_files_list[:nmax]\n",
    "    good_files_list = desc_files_list\n",
    "    \n",
    "    tasks = partial(SelectDesc, good_path_loc, cont_name_desc, desc_folder_rem)\n",
    "    with multiprocessing.Pool(1) as p:\n",
    "        result = list(tqdm.tqdm_notebook(p.imap(tasks, desc_files_list), total=len(desc_files_list)))\n",
    "    \n",
    "    # List the bad garchim descriptor files\n",
    "    print('Bad Garchim files...')\n",
    "    desc_files_list = []\n",
    "    desc_folder_rem = method_dir + '/' + desc_blob_sub_dir + extension\n",
    "    BlobList(cont_name_desc, desc_folder_rem, desc_files_list)\n",
    "    desc_files_list = [s.replace('/','') for s in desc_files_list]\n",
    "    desc_files_list = [s for s in desc_files_list if s in bad_files_garchim]\n",
    "    desc_folder_rem = method_dir + '/' + desc_blob_sub_dir + extension\n",
    "    badg_path_loc = path_loc + '/badg/' + desc_blob_sub_dir + extension\n",
    "    nfiles = len(desc_files_list)\n",
    "    random.shuffle(desc_files_list)\n",
    "    \n",
    "    if nfiles>nmax:\n",
    "        desc_files_list = desc_files_list[:nmax]\n",
    "    badg_files_list = desc_files_list\n",
    "\n",
    "    tasks = partial(SelectDesc, badg_path_loc, cont_name_desc, desc_folder_rem)\n",
    "    with multiprocessing.Pool(1) as p:\n",
    "        result = list(tqdm.tqdm_notebook(p.imap(tasks, desc_files_list), total=len(desc_files_list)))\n",
    "    \n",
    "    # List the bad nicolas descriptor files\n",
    "    print('Bad Nicolas files...')\n",
    "    desc_files_list = []\n",
    "    desc_folder_rem = method_dir + '/' + desc_blob_sub_dir + extension\n",
    "    BlobList(cont_name_desc_cor, desc_folder_rem, desc_files_list)\n",
    "    badn_path_loc = path_loc + '/badn/' + desc_blob_sub_dir + extension\n",
    "\n",
    "    # Erase corrupted files from the list\n",
    "    desc_files_list = [s.replace('/','') for s in desc_files_list if s not in bad_files_garchim]\n",
    "    nfiles = len(desc_files_list)\n",
    "    random.shuffle(desc_files_list)\n",
    "    \n",
    "    if nfiles>nmax:\n",
    "        desc_files_list = desc_files_list[:nmax]\n",
    "    badn_files_list = desc_files_list\n",
    "    \n",
    "    tasks = partial(SelectDesc, badn_path_loc, cont_name_desc_cor, desc_folder_rem)\n",
    "    with multiprocessing.Pool(1) as p:\n",
    "        result = list(tqdm.tqdm_notebook(p.imap(tasks, desc_files_list), total=len(desc_files_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
